---
title: 人工智能基础
key: 20180928
tags: 人工智能 
mathjax: true
mathjax_autoNumber: false
---

## AI和机器学习发展简史

### 人工智能历史与现状
人工智能正名与 1956 年的 Darthmouth 会议，会议提出 **学习或者智能的任何特征都能够被精确地加以描述，是的机器可以对其进行模拟** 。
<!--more-->
人工智能学派受二十世纪数学哲学的影响，分为三个学派
- 形式主义：所有数学分支都可以公理化 
- 逻辑主义：一切数学都是建立在数理逻辑基础上
- 构造主义：存在就是被构造

当前三大学派逐渐走向融合，随着 AlphaGo 的兴起，随机模拟方法显得越来越重要。

### 机器学习发展历程
人工智能四要素：算法、算力、数据、场景。

人工智能包含机器学习、机器学习包含深度学习。

#### 轻量机器学习
机器学习需要海量数据与算力做训练，在很多场景下数据与算力都有限，不能部署大规模机器学习（训练），因此近期有一种 **轻量机器学习技术**，具备如下特点：
- 计算复杂度低
- 具备一定的在线学习能力：不需要大量存储训练样本，一边处理一遍学习（更新模型）
- 先验知识起点高：在数据量少的情况下，依然可以进行模型更新与推断。如贝叶斯统计推断。
- 可利用近似计算寻求满意解，使之非常接近最优解，同时大大降低计算复杂度

#### 机器学习/模式识别关键技术
1. 无监督学习：不需要标注数据
- k-均值聚类
- 层级聚类
- 自组织映射

2. 有监督学习：需要标注数据
- 参数方法：最大似然估计，期望最大化算法，隐Markov模型，回归模型
- 非参数方法：基于实例的方法（近邻法、核密度法），决策树（ID 3/4/5, CART）
- 贝叶斯方法：先验分布的设定，后验分布的设定，贝叶斯神经网络，贝叶斯回归模型
- 核方法：高斯过程，关联向量机，核PCA
- 几何方法：支持向量机，流行学习
- 概率图模型：贝叶斯网络，Markov随机场
- 神经网络：后传播算法，深度学习（CNN, RNN）

3. 强化学习：子学习，类似AlphaGo通过自己与自己对战学习
- 无模型：策略迭代，策略搜索
- 有模型：深度强化学习

4. 随机模拟技术
- 常见分布的随机数产生器
- Markov 链
- Monte Carlo Gibbs采集器

5. 统计决策
- 贝叶斯期望损失
- 极大极小原则
- 贝叶斯风险原则

6. 学习策略
- 生成学习（自助聚集、梯度提升）
- 增量学习
- 迁移学习

7. 轻量机器学习
- 轻量模型（计算复杂度低）
- 在线学习（不存储训练数据）
- 近似计算（求满意解，减低复杂度）
- 基于受限领域知识的规则方法
- 贝叶斯统计推断

#### 机器学习现状：百家争鸣
- 经典方法：基于单一数据表示的最优化
- 深度学习：特征的学习和数据表示的层级化
- Monte Carlo 计算方法：用随机模拟方法求近似解（随机模拟方法的大量应用：如AlphaGo的核心技术 Monte Carlo 树搜索）
- 统计决策学习：基于知识的小样本学习和决策规则学习

## 机器学习算法入门

### 概述
这里的机器学习算法内容包含 **机器学习基础与框架** 与 **机器学习应用实例与方法** ，主要涉及如下的算法：
- 线性回归
- 梯度下降
- 判决树
- 逻辑回归
- 神经网络
- 支持向量机
- 朴素贝叶斯
- 聚类

### 机器从哪里学习？机器学习是什么？
机器从数据中学习。
**机器学习 ~= 寻找一个函数**

如：
- 语音识别： f(一段语音) = 一段文字
- 图像识别：f(一张图片) = 一段文字描述

### 机器学习三种分类（当前最成功的是监督学习）
#### 1. 监督学习（任务驱动） Supervised learning
训练数据有标签，数据标签可理解为教师
- 识别
- 分类
- 回归

#### 2. 无监督学习（数据驱动） Unsupervised learning
训练数据无标签
- 聚类

#### 3. 强化学习（与环境互动）  Reinforcement learning
输出结果不能立即知道好坏，需要与环境互动。如下围棋。

### 监督学习框架（以图像识别为例）
监督学习（模型训练）的步骤：
- 标注训练数据
- 定义模型
- 定义模型中函数的"好"/"坏"
- 找到最好的函数

找到最好的函数之后，使用实际数据验证，这个就是 **推理** 。

- 线性回归算法/梯度下降算法：通过标注数据拟合线性函数，训练好模型的函数是一个线性函数

- 多项式回归算法：通过标注数据拟合曲线函数，训练好的模型是一个曲线函数；典型应用如房价预测

- 决策树：利用树模型来描述决策分析问题；决策树中包含决策节点、状态节点和结果节点；典型应用如App推荐

- 逻辑回归/神经网络/支持向量机/支持向量机核技巧: 逻辑回归用于分类，神经网络用于复杂分类，支持向量机用于评判多个逻辑回归的好坏

- 朴素贝叶斯: 垃圾邮件检测(Paul Graham's Method)

- 披萨店选址 - K-Means 聚类算法: 属于 **无监督类学习**

## 神经网络入门

### 名词: ANN(人工神经网络), ALNN

### 选西瓜例子
吃了一个夏天西瓜，总结出好吃的西瓜的四个因素：底部圈圈小/瓜蒂卷/颜色青/纹路整齐，四个变量使用分类器函数，得出一个评分，评判西瓜是否好吃。

### 人工神经元(M-P Model)与单层感知器(Single-Layer Perceptron)

生物神经元 Biological Neuron 工作原理: 
1. synapses 收集到信号
2. nucles 处理信号
3. 通过dendrites 输出信号，给另外一个神经元的 synapses

模仿生物神经元 Artifical Neuron 工作原理：
1. 输入变量 $$x_i$$ 与对应的权重 $$w_i$$ 
2. 加全求和 $$sum_{i}{N} x_i*w_i$$
3. 求和值作为激活函数(Treshold Unit)函数的输入

### XOR & 多层感知器(Multi-Layer Perceptron)

### BP(Back Propagation) 算法原理

BP 算法属于有监督学习的一种。

原理：
1. 计算加权求和，输出作为激活函数的输入
2. 通过指定期望值，计算激活函数输入与期望值之间的方差
3. 通过梯度下降函数调整初始输入，直到找到一个最佳方差值

局限：
1. 可能会落入局部最优，因为算法看不到全局
2. 训练步伐太大可能会错过最优值从而导致不收敛

### 其他神经网路算法

- Hebb Rule: 根据生物条件发射思想
- Self-organizing Hohonen Rule: 胜者全取，无监督学习。
- Hopfield law: 热力学能量定理与神经网络模型关联，神经网络中每个神经元视作为一个状态机，整个网络被定义为一个能量函数，能量函数最小值就是迭代的终点，最优点。解决经典的旅行推销员问题。
- LMS algorithm(Latest Mean Square): 最小方差计算偏差，学习方法是梯度下降。
- Competitive Learning: 竞争学习，无监督学习方法，胜者全取。