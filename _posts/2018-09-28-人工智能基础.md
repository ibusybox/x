---
title: 人工智能基础
key: 20180928
tags: 人工智能 
mathjax: true
mathjax_autoNumber: false
---

## AI和机器学习发展简史

### 人工智能历史与现状
人工智能正名与 1956 年的 Darthmouth 会议，会议提出 **学习或者智能的任何特征都能够被精确地加以描述，是的机器可以对其进行模拟** 。
<!--more-->
人工智能学派受二十世纪数学哲学的影响，分为三个学派

- 形式主义：所有数学分支都可以公理化 
- 逻辑主义：一切数学都是建立在数理逻辑基础上
- 构造主义：存在就是被构造

当前三大学派逐渐走向融合，随着 AlphaGo 的兴起，随机模拟方法显得越来越重要。

### 机器学习发展历程
人工智能四要素：算法、算力、数据、场景。

人工智能包含机器学习、机器学习包含深度学习。

#### 轻量机器学习
机器学习需要海量数据与算力做训练，在很多场景下数据与算力都有限，不能部署大规模机器学习（训练），因此近期有一种 **轻量机器学习技术**，具备如下特点：
- 计算复杂度低
- 具备一定的在线学习能力：不需要大量存储训练样本，一边处理一遍学习（更新模型）
- 先验知识起点高：在数据量少的情况下，依然可以进行模型更新与推断。如贝叶斯统计推断。
- 可利用近似计算寻求满意解，使之非常接近最优解，同时大大降低计算复杂度

#### 机器学习/模式识别关键技术
1. 无监督学习：不需要标注数据
- k-均值聚类
- 层级聚类
- 自组织映射

2. 有监督学习：需要标注数据
- 参数方法：最大似然估计，期望最大化算法，隐Markov模型，回归模型
- 非参数方法：基于实例的方法（近邻法、核密度法），决策树（ID 3/4/5, CART）
- 贝叶斯方法：先验分布的设定，后验分布的设定，贝叶斯神经网络，贝叶斯回归模型
- 核方法：高斯过程，关联向量机，核PCA
- 几何方法：支持向量机，流行学习
- 概率图模型：贝叶斯网络，Markov随机场
- 神经网络：后传播算法，深度学习（CNN, RNN）

3. 强化学习：子学习，类似AlphaGo通过自己与自己对战学习
- 无模型：策略迭代，策略搜索
- 有模型：深度强化学习

4. 随机模拟技术
- 常见分布的随机数产生器
- Markov 链
- Monte Carlo Gibbs采集器

5. 统计决策
- 贝叶斯期望损失
- 极大极小原则
- 贝叶斯风险原则

6. 学习策略
- 生成学习（自助聚集、梯度提升）
- 增量学习
- 迁移学习

7. 轻量机器学习
- 轻量模型（计算复杂度低）
- 在线学习（不存储训练数据）
- 近似计算（求满意解，减低复杂度）
- 基于受限领域知识的规则方法
- 贝叶斯统计推断

#### 机器学习现状：百家争鸣
- 经典方法：基于单一数据表示的最优化
- 深度学习：特征的学习和数据表示的层级化
- Monte Carlo 计算方法：用随机模拟方法求近似解（随机模拟方法的大量应用：如AlphaGo的核心技术 Monte Carlo 树搜索）
- 统计决策学习：基于知识的小样本学习和决策规则学习

## 机器学习算法入门

## 神经网络入门

